{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb865ec2",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Classification Metrics\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC June 2022\n",
    "<p>Phase 3: Topic 26</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e169a6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6780e",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many classification metrics for evaluating model validation/test set performance:\n",
    "\n",
    "- Changes which model you will pick during hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01e0b5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choice of evaluation metric:\n",
    "- Major impact on how well model serves its intended goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006e9f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Scenario: Identifying Fraudulent Credit Card Transactions\n",
    "<center><img src = \"Images/credit_card.png\" width = 400/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f154b22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4161dfa2",
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    10000 non-null  float64\n",
      " 1   V1      10000 non-null  float64\n",
      " 2   V2      10000 non-null  float64\n",
      " 3   V3      10000 non-null  float64\n",
      " 4   V4      10000 non-null  float64\n",
      " 5   V5      10000 non-null  float64\n",
      " 6   V6      10000 non-null  float64\n",
      " 7   V7      10000 non-null  float64\n",
      " 8   V8      10000 non-null  float64\n",
      " 9   V9      10000 non-null  float64\n",
      " 10  V10     10000 non-null  float64\n",
      " 11  V11     10000 non-null  float64\n",
      " 12  V12     10000 non-null  float64\n",
      " 13  V13     10000 non-null  float64\n",
      " 14  V14     10000 non-null  float64\n",
      " 15  V15     10000 non-null  float64\n",
      " 16  V16     10000 non-null  float64\n",
      " 17  V17     10000 non-null  float64\n",
      " 18  V18     10000 non-null  float64\n",
      " 19  V19     10000 non-null  float64\n",
      " 20  V20     10000 non-null  float64\n",
      " 21  V21     10000 non-null  float64\n",
      " 22  V22     10000 non-null  float64\n",
      " 23  V23     10000 non-null  float64\n",
      " 24  V24     10000 non-null  float64\n",
      " 25  V25     10000 non-null  float64\n",
      " 26  V26     10000 non-null  float64\n",
      " 27  V27     10000 non-null  float64\n",
      " 28  V28     10000 non-null  float64\n",
      " 29  Amount  10000 non-null  float64\n",
      " 30  Class   10000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d10a67",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The dataset contains a bunch of features:\n",
    "- The transaction amount\n",
    "- The relative time of the transaction\n",
    "- V1-V28 are relevant features: product of feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9572360",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fraud transaction algorithms:\n",
    "- Typically huge number of features \n",
    "- Can create small combination of features that encompass most variation in the full feature set:\n",
    "    - Principal component analysis (PCA)\n",
    "    - V1-V28 are these combination features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49176b",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Target 'Class':\n",
    "- 1 if the transaction was fraudulent\n",
    "- 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e857f5b",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c53546",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9962\n",
       "1      38\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a536cad",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What have we just learned about our target in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3e039",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Run a logistic regression on the credit card fraud data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90f4e2f",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "X = credit_data.drop('Class', axis = 1)\n",
    "y = credit_data['Class']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "cred_scaler = StandardScaler()\n",
    "cred_scaler.fit(X_train)\n",
    "X_train_sc = cred_scaler.transform(X_train)\n",
    "X_test_sc = cred_scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb45a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319ed9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Remember:\n",
    "- .score(X,y) gets the accuracy of our classification model on predicting y given X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6caa91",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9d8e9",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We got 99.88% accuracy! \n",
    "- Our model is good. Right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f1cd4c",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Think again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8b9b5",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "- Fraction of correct classifications.\n",
    "- What the `.score()` method calculates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a02b9",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Class 1 (Fraud) = Our positive class**\n",
    "\n",
    "- TP: True positive\n",
    "- FP: False positive\n",
    "- TN: True negative\n",
    "- FN: False negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97fee9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Easy way to unpack the TP, TN, FP, FN is using the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8fb44d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix #nice function to visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2538d2fd",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2493,    0],\n",
       "       [   3,    4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "y_pred = cred_model.predict(X_test_sc) \n",
    "# calculate confusion matrix\n",
    "cfmat = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "cfmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf7333",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So it displays:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "TN & FP \\\\\n",
    "FN & TP\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50bff038",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a5a4ba7",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493 0 3 4\n",
      "[[2493    0]\n",
      " [   3    4]]\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cfmat.flatten()\n",
    "print(tn,fp,fn,tp)\n",
    "\n",
    "print(cfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb2a3ff5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635afca6",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "In words: How often did my model correctly identify transactions (fraudulent or not fraudulent)? This should give us the same value as we got from the `.score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b558d831",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988\n"
     ]
    }
   ],
   "source": [
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dee7bc5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9532f6",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "My accuracy is great. But is our model doing well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714350d",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## True positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f14db30",
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true positives\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9011cd0a",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096a9ea",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model not doing well on fraud detection.\n",
    "\n",
    "But the accuracy is great. What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94452e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Accuracy is not a great metric when:\n",
    "- There's a class imbalance\n",
    "- When we care about the positive detections rate for *each* given class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42d761",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A better metric (for this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24cdec",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Precision** = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "In this case: \n",
    "- Of the model's prediction of 'fraudulent', how many of those predictions were correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21329363",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac8410ab",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = tp/(tp+fp)\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfd99e4",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811fd6d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the given task of detecting credit card fraud:\n",
    "    \n",
    "Is precision something that the credit card company cares a lot about?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa328b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another metric that could be important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75849da",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Recall** = **Sensitivity** = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "Of the actual fraudulent transactions in our data, how many did our model predict as fraudulent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "926080a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d65fb41",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "rec = tp / (tp + fn)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c91e74",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00014453",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this task, is recall an important metric? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54a292",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A metric balancing both recall and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6e807b8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34348865",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An $F$-score is a combination of precision and recall, which can be useful when both are important. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a0d84",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The $F_1$ score is an equal balance of the two using a [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean).\n",
    "\n",
    "$$F_1 = 2 \\frac{Precision \\cdot Recall}{Precision + Recall} = \\\\ \\frac{2TP}{2TP + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5773d572",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "f1_sc = 2*prec*rec / (prec + rec)\n",
    "print(f1_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b01f40",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373885b",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which of these metrics do you think a credit card company would care most about when trying to flag fraudulent transactions to deny?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6421d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `classification_report()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c29d42d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b3677de",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2493\n",
      "           1       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      0.79      0.86      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70c9b9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The top rows show statistics for if you treated each label as the \"positive\" class\n",
    "- **Support** shows the sample size in each class\n",
    "- The averages in the bottom two rows are across the rows in the class table above (useful when there are more than two classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715bbd13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another example: Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37635889",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950f347",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Load the data and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d137667a",
   "metadata": {
    "cell_style": "center",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "cancer_data_dict = load_breast_cancer()\n",
    "X_cancer = cancer_data_dict['data']\n",
    "cancer_feature_names = cancer_data_dict['feature_names']\n",
    "\n",
    "cancer_features = pd.DataFrame(X_cancer, columns = cancer_feature_names)\n",
    "cancer_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59d9404a",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cancer = cancer_data_dict['target']\n",
    "cancer_data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3909d1",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - 0 = malignant\n",
    " - 1 = Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "259ea64c",
   "metadata": {
    "cell_style": "center",
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(cancer_features, y_cancer,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2525cb",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Standard scale and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bdd1890",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data\n",
    "bc_scaler = StandardScaler()\n",
    "bc_scaler.fit(X_train_bc)\n",
    "X_train_sc = bc_scaler.transform(X_train_bc)\n",
    "X_test_sc = bc_scaler.transform(X_test_bc)\n",
    "\n",
    "# Run the model\n",
    "bc_model = LogisticRegression(solver='lbfgs', max_iter=10000, random_state=42)\n",
    "bc_model.fit(X_train_sc, y_train_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de2463",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d65977f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = bc_model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0ed1a",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculate the following for this model:\n",
    "(scikit-learn's functions for this)\n",
    "\n",
    "- Confusion Matrix\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa765738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c62ffd25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Which of these metrics matter for this breast cancer detection problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f10a67",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Which metric to tune model hyperparameters with?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2eb626",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Accuracy: misleading under class imbalance(A lottery-ticket predictor that *always* predicts a loser will be highly accurate.)\n",
    "    - Sometimes just fine.\n",
    "- Precision: when false positives are much worse than false negatives\n",
    "    - DNA crime-scene forensics.\n",
    "- Recall: when false negatives are a lot worse \n",
    "    - X-ray imaging for cancer prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b914752",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282049a",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "**Multiclass classification**: more than two possible values for the target. An example:\n",
    "\n",
    "- Classifying iris sub-species based on petal/sepal characteristics.\n",
    "\n",
    "<center><img src = \"Images/iris-dataset.png\" width = 500 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449a64d",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Same metrics/methods to evaluate our models:\n",
    "- Confusion matrices: number of rows/columns equal to the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2008116",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Metrics (precision/recall):\n",
    "    - choose one class to be the \"positive\" class.\n",
    "    - rest are assigned to the \"negative\" class. \n",
    "    - compute precision/recall for given \"positive\" class.\n",
    "\n",
    "Repeat for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a6de86f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77698db1",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = load_iris()\n",
    "X = data_dict['data']\n",
    "features = pd.DataFrame(X, columns = data_dict['feature_names'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32d87940",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_dict['target']\n",
    "data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9985d",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 0 = setosa\n",
    "- 1 = versicolor\n",
    "- 2 = virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d992b269",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train-test split \n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(features, y, test_size = 0.3, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "000709a3",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Scale and transform\n",
    "iris_scaler = StandardScaler()\n",
    "X_train_iris_sc = iris_scaler.fit_transform(X_train_iris)\n",
    "X_test_iris_sc = iris_scaler.transform(X_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83f84988",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fit model and get predictions\n",
    "iris_model = LogisticRegression(max_iter = 10000)\n",
    "iris_model.fit(X_train_iris_sc, y_train_iris)\n",
    "y_pred_iris = iris_model.predict(X_test_iris_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a060dc55",
   "metadata": {
    "cell_style": "center",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(iris_model, X_test_iris_sc, \n",
    "                      y_test_iris);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be671a",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our confusion matrix for the multiclass iris problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5bd7175",
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_iris, y_test_iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fe5aa",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some issues with assessing the quality of a model solely on these metrics:\n",
    "- Need to think a little bit more carefully about probabilities and classification thresholds\n",
    "- The reciever operation curve (up next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692c786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
