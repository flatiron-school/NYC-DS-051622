{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Unsupervised Learning: Clustering and K-Means\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC July 2022\n",
    "<p>Phase 4: Topic 35</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from src.demo_images import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Goals\n",
    "- Assess what scenarios could use $k$-means\n",
    "- Articulate the methodology used by $k$-means\n",
    "- Apply KMeans from sklearn.cluster to a relevant dataset\n",
    "- Select the appropriate number of clusters using the elbow method and Silhouette Scores\n",
    "- Evaluate the weaknesses and remedies to $k$-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Often don't have labels on data:\n",
    "\n",
    "- Discover the structure in the data.\n",
    "- Is there some kind of grouping in the data?\n",
    "- Maybe discover relationship between subsets of the data \n",
    "- Its true dimensionality, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Goals are much less clear here:\n",
    "- We are not creating a prediction machine.\n",
    "- Instead we are recognizing patterns and uncovering relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Examples with clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are no training labels here. Just data points:\n",
    "    \n",
    "- Our eyes can make out regions.\n",
    "- But we want a computer to do this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_csv('Data/s1cluster.txt', delimiter = '\\s+ ', header = None, names = ['X1', 'X2'], engine = 'python')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One example of some value:\n",
    "- recognizing/labeling and segmenting different types of cell tissue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/clustercells.png\" width = 600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Discretize image.\n",
    "- Clustering grid-cell in color-value space of RGB image\n",
    "- Discover regions of epithelial vs. non-epithelial cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another example might be segmenting customers into groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/initialscenario.png\" width = 500/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Discovering different types of customers within purchase data:\n",
    "\n",
    "- Could potentially segment into 4 groups?\n",
    "- Obviously targeted ads/deals, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### So what do you do with clustering results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once clusters are identified:\n",
    "- Can use discovered clusters as a feature in a predictive task.\n",
    "- e.g., predict churn rate using customer cluster assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- *How were target labels in classification made in the first place?*\n",
    "\n",
    "- Discovered clusters becomes _**target labels**_:\n",
    "- Original data features and cluster assignment as training data for classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Our first clustering algorithm: KMeans\n",
    "- Assuming $K$ clusters\n",
    "- Assuming cluster centers (or centroids).\n",
    "- Assign each data points to each of the $K$ clusters\n",
    "    - pick cluster whose centroid is closest to data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An iterative process:\n",
    "\n",
    "- Dont know cluster centroids.\n",
    "- Data points: don't know cluster assignments.\n",
    "\n",
    "#### Can help use one to find the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Pick a random set of cluster center positions.\n",
    "- Assign clusters to data points\n",
    "- Data points and their cluster assignments:\n",
    "    - get mean of data in each cluster\n",
    "    - update centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/kmeans.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It can be shown the procedure lowers the cost function:\n",
    "\n",
    "$$L = \\sum_{i=1}^N \\sum_{k = 1}^K \\mathbb{1}(c_i = k)|x_i - \\mu_k|^2 $$\n",
    "\n",
    "where $ \\mathbb{1}(c_i = k) = 1$ if $x_i$ assigned to cluster $k$ else 0.\n",
    "\n",
    "- Cost function known as **inertia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Kill iterations once convergence reached.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<img src = \"Images/kmeans_withobjective.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "KMeans is a distanced based algorithm. \n",
    "- We need to scale first then do the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), \n",
    "         ('kmc', KMeans(n_clusters = 15) ) ]\n",
    "kmc_pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmc_pipe.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**KMeans attributes**\n",
    "\n",
    "- .cluster_centers_ attribute: fitted centroid locations\n",
    "- .labels_ attribute: cluster assignments for each data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The centers are scaled:\n",
    "- Need to unscale back to original data scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scld_centers = kmc_pipe['kmc'].cluster_centers_\n",
    "kc_centers = kmc_pipe['scaler'].inverse_transform(scld_centers)\n",
    "\n",
    "# class labels for each observation\n",
    "class_assignment = kmc_pipe['kmc'].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X['label'] = class_assignment\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Visualize cluster assigment/visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"tab10\")\n",
    "\n",
    "sns.scatterplot(x = 'X1', y = 'X2', hue = 'label', palette=sns.color_palette('tab10', n_colors= 15), data = X)\n",
    "sns.scatterplot(x = kc_centers[:,0], y = kc_centers[:,1], color = 'blue', s = 80)\n",
    "#plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%capture clusterplot \n",
    "sns.set_palette(\"tab10\")\n",
    "\n",
    "sns.scatterplot(x = 'X1', y = 'X2', hue = 'label', palette=sns.color_palette('tab10', n_colors= 15), data = X)\n",
    "sns.scatterplot(x = kc_centers[:,0], y = kc_centers[:,1], color = 'blue', s = 80)\n",
    "#plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Class assignment for a given test point:\n",
    "- .predict() method for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmc_pipe.predict([[0.5e6 , 0.8e6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "clusterplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Elbow method: choosing the appropriate number of $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "KMeans inertia: can also get final value of loss function at convergence.\n",
    "- This is important: can help us use as a diagnostic tool. \n",
    "- Help us pick $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$L = \\sum_{i=1}^N \\sum_{k = 1}^K \\mathbb{1}(c_i = k)|x_i - \\mu_k|^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmc_pipe['kmc'].inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Issue:\n",
    "- Adding more and more centroids (increasing K)\n",
    "- Arbitrarily decreases the convergence value of the inertia.\n",
    "- More centroids: much lower squared distance of a point to *some* centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$L = \\sum_{i=1}^N \\sum_{k = 1}^K \\mathbb{1}(c_i = k)|x_i - \\mu_k|^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define inertia vs K plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_inertias(X, K, increment, kmc_pipe):\n",
    "\n",
    "    klist = np.arange(1,K,increment)\n",
    "    inertia_list = []\n",
    "    for k in klist:\n",
    "        kmc_pipe.steps.pop(-1)\n",
    "        kmc_pipe.steps.append(('kmc', \n",
    "                               KMeans(\n",
    "                                   n_clusters = k)))\n",
    "        kmc_pipe.fit(X)\n",
    "\n",
    "        inertia = kmc_pipe['kmc'].inertia_\n",
    "        inertia_list.append(inertia)\n",
    "        \n",
    "    plt.plot(klist, inertia_list)\n",
    "    plt.ylabel('Final inertia')\n",
    "    plt.xlabel('K')\n",
    "    plt.title('Elbow plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take in a very simple data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_simple = pd.read_csv('Data/xclara.txt').drop(columns = ['Unnamed: 0'])\n",
    "X_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'V1', y = 'V2', data = X_simple)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimal cluster number at/near elbow/kink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Inertia decreases sharply until it hits optimal cluster number:\n",
    "- Then increasing number makes marginal gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The behavior of inertia as a function of K is almost never this clean:\n",
    "- well separated clusters\n",
    "- similar sizes, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X_simple, 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example with our old dataset: a little less good.\n",
    "\n",
    "A good choice might be k = 15 (whis the real cluster number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X, 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_s4 = pd.read_csv('Data/s4cluster.txt', delimiter = '\\s+ ', header = None, names = ['X1', 'X2'], engine = 'python')\n",
    "X_s4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X_s4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Looks like a mess. But this kind of mess is typical.\n",
    "- A hexbin density plot reveals the clustering structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x= 'X1', y= 'X2', kind=\"hex\", data = X_s4, color=\"#4CB391\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X_s4, 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Doesn't work very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When there is a lot of overlap, sum of squared errors decreases smoothly with number of centroids.\n",
    "- Need a better/more meaningful metric to measure effectiveness of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The silhouette coefficient\n",
    "A more principled way of measuring clustering effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The notion of **cohesion**: \n",
    "- how tightly bound is a point in a given cluster to its cluster members?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The notion of **differentiation**: \n",
    "- how far away is a point in a given cluster from points in other clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<img src = \"Images/silhouette_distance.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Cohesiveness**\n",
    "\n",
    "$$ a(i) = \\overline{d(x_i, x_j)} $$ \n",
    "\n",
    "for $j$ indexing points in same clusters as point $i$.\n",
    "\n",
    "**Average of distance of $i$ to its clustermates.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Differentiation**\n",
    "\n",
    "$$ b(i) = \\overline{d(x_i, x_k)} $$ \n",
    "\n",
    "for $k$ indexing points in nearest neighboring cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Silhouette index\n",
    "\n",
    "Measuring binding of a point to its own cluster vs. neighboring cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Silhouette index for point $i$:\n",
    "$$ s(i) = \\frac{b(i) - a(i)}{\\max(a(i),b(i))} $$\n",
    "\n",
    "- When $a(i)$ is very small compared to $b(i)$:\n",
    "    - Point $i$ much more tightly bound to clustermates than neighboring cluster.\n",
    "    - $s(i) \\rightarrow 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When $a(i)$ is very large compared to $b(i)$:\n",
    "    - Point $i$ closer to points in neighboring cluster than its own.\n",
    "    - $s(i) \\rightarrow -1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Visualizing silhouette index for entire dataset:\n",
    "- cohesiveness/differentiation for each assigned cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's evaluate clustering on our trickiest clustering dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), \n",
    "         ('kmc', KMeans(n_clusters = 15) ) ]\n",
    "kmc_pipe = Pipeline(steps)\n",
    "X_s4['clstr_labels'] = kmc_pipe.fit_predict(X_s4[['X1', 'X2']])\n",
    "X_s4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"tab10\")\n",
    "scld_centers = kmc_pipe['kmc'].cluster_centers_\n",
    "kc_centers = kmc_pipe['scaler'].inverse_transform(scld_centers)\n",
    "sns.scatterplot(x = 'X1', y = 'X2', hue = 'clstr_labels', palette=sns.color_palette('tab10', n_colors= 15), data = X_s4)\n",
    "sns.scatterplot(x = kc_centers[:,0], y = kc_centers[:,1], color = 'blue', s = 80)\n",
    "#plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fitted centroids and the centers of density line up well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x= 'X1', y= 'X2', kind=\"hex\", data = X_s4, color=\"#4CB391\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Scikit-learn can calculate silhouette index for each data point given cluster labels:\n",
    "\n",
    "- silhouette_samples(data, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let'd do this on our clustering result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_samples(X_s4[['X1', 'X2']],\n",
    "                   X_s4['clstr_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_s4['silhouette'] = silhouette_samples(X_s4[['X1', 'X2']],\n",
    "                   X_s4['clstr_labels'])\n",
    "\n",
    "X_s4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One useful plot is a barplot of the average silhouette index for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "col_list = ['clstr_labels', 'silhouette']\n",
    "silh_idx_avgs = X_s4[col_list].groupby('clstr_labels').mean().sort_values(by = 'silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "silh_idx_avgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A visual of the cohesion/differentiation by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = 'silhouette', \n",
    "            y = 'clstr_labels', orient = 'h',\n",
    "            data = silh_idx_avgs.reset_index())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An often used visual is the silhouette plot.\n",
    "- More information than average silhouette score by cluster.\n",
    "- Distribution of silhouette indices by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def silhouette_plot(Xclustered_scores):\n",
    "    \n",
    "    n_clusters = 15\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (8,11))\n",
    "\n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    ax.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = Xclustered_scores[Xclustered_scores['clstr_labels'] == i].silhouette\n",
    "\n",
    "        ith_cluster_silhouette_values = ith_cluster_silhouette_values.sort_values(ascending = True)\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "\n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_plot(X_s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Distribution of silhouette indices grouped by cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparing plot by plot for each realization of $k$:\n",
    "- comprehensive but also may want a quick/dirty metric for tuning K\n",
    "- **The silhouette score**: average silhouette index over all samples\n",
    "    - the better the clustering solution, the higher the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_score(X_s4[['X1', 'X2']], X_s4['clstr_labels'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Plotting silhouette coefficient vs. K\n",
    "- Plot/metric for finding a plausible K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def plot_silh_scores(X, K, increment, kmc_pipe):\n",
    "\n",
    "    klist = np.arange(4,K,increment)\n",
    "    score_list = []\n",
    "    for k in klist:\n",
    "        kmc_pipe.steps.pop(-1)\n",
    "        kmc_pipe.steps.append(('kmc', \n",
    "                               KMeans(\n",
    "                                   n_clusters = k)))\n",
    "        clstr_labels = kmc_pipe.fit_predict(X)\n",
    "\n",
    "        score = silhouette_score(X, clstr_labels)\n",
    "        score_list.append(score)\n",
    "        \n",
    "    sns.lineplot(x = klist, y = score_list, color = 'r')\n",
    "    plt.ylabel('Silhouette Coefficient')\n",
    "    plt.xlabel('K')\n",
    "    plt.title('Silhouette coefficient plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The maximum silhouette score is clearly at k = 15:\n",
    "- matches our exact cluster number even with our trickier dataset.\n",
    "- elbow plot tells us nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_silh_scores(X_s4[['X1', 'X2']], \n",
    "                 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X_s4[['X1', 'X2']], \n",
    "              30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### **Limitations** of $k$-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Ideal $k$-means scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ideal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### KMeans works well when:\n",
    "\n",
    "- Balanced cluster sizes\n",
    "- Clusters have similar density\n",
    "- Spherical clusters/equal variance of variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 1 - classes not all round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "messyOne()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 2 - imbalanced class size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "messyTwo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 3 - class size and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "messyThree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Solution to challenges:\n",
    "\n",
    "- Try different clustering methods:\n",
    "- e.g., Gaussian mixtures, DBSCAN, Hierarchical clustering, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $k$-means on larger dataset - Wine subscription\n",
    "\n",
    "You want to run a wine subscription service, but you have no idea about wine tasting notes. You are a person of science.\n",
    "You have a wine dataset of scientific measurements.\n",
    "If you know a customer likes a certain wine in the dataset, can you recommend other wines to the customer in the same cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Questions:\n",
    "- How many clusters are in the wine dataset?\n",
    "- What are the characteristics of each clusters?\n",
    "- What problems do you see potentially in the data?\n",
    "\n",
    "the dataset is `Wine.csv`\n",
    "\n",
    "Instructions:\n",
    "- First, remove customer_segment from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Work on problem here: Would scaling make a difference?\n",
    "wine = pd.read_csv('data/Wine.csv')\n",
    "wine.drop(columns=['Customer_Segment'], inplace=True)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review $k$-means steps\n",
    "1. Look at and clean data (if needed)\n",
    "2. Scale data\n",
    "3. Try various values of $k$\n",
    "4. Plot SSE and Silhouette coefficient to find best $k$\n",
    "5. Describe the characteristics of each cluster using their centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How many clusters fit the data?\n",
    "\n",
    "What can you tell me about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "    <code>from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler().fit(wine)\n",
    "wine_scaled = ss.transform(wine)\n",
    "silhouette_scores = []\n",
    "for j in range(2, 20):\n",
    "    clusters = KMeans(n_clusters=j, random_state=42)\n",
    "    cluster_labels = clusters.fit_predict(wine)\n",
    "    silhouette = metrics.silhouette_score(wine, cluster_labels)\n",
    "    silhouette_scores.append(silhouette)\n",
    "print(np.argmax(silhouette_scores)) # The best number of clusters is 2.\n",
    "best = KMeans(n_clusters=2, random_state=42)\n",
    "wine['cluster'] = best.fit_predict(wine)\n",
    "print(wine.groupby('cluster').mean())\n",
    "print(best.cluster_centers_)</code>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
